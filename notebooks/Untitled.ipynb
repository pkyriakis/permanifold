{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils, math\n",
    "from persistence_diagram import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import manifolds\n",
    "\n",
    "\n",
    "class PManifold(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        Model definition for the Persistent Manifold Layer\n",
    "        The input to this layer is a peristence diagram with\n",
    "        its points embedded in a m-dim Euclidean space\n",
    "    '''\n",
    "\n",
    "    def __init__(self, max_num_of_points, man_dim, num_of_hom, K, manifold='poincare'):\n",
    "        '''\n",
    "            Initializes layer params, i.e theta's\n",
    "        '''\n",
    "        super(PManifold, self).__init__()\n",
    "        self.K = K\n",
    "        self.num_of_hom = num_of_hom\n",
    "        self.max_num_of_points = max_num_of_points\n",
    "        self.man_dim = man_dim\n",
    "\n",
    "        if manifold == 'poincare':\n",
    "            self.manifold = manifolds.Poincare(man_dim=man_dim)\n",
    "        if manifold == 'euclidean':\n",
    "            self.manifold = manifolds.Euclidean()\n",
    "        if manifold == 'lorenz':\n",
    "            self.manifold = manifolds.Lorenz(man_dim=man_dim)\n",
    "\n",
    "        self.x_o = tf.random.normal(shape=(self.man_dim,))  # the fixed point on the manifold\n",
    "        self.x_o = self.manifold.project_to_manifold(self.x_o)\n",
    "\n",
    "        theta_init = tf.random_uniform_initializer()\n",
    "        self.theta = tf.Variable(name='theta',\n",
    "                                 initial_value=theta_init(shape=(self.num_of_hom,\n",
    "                                                                 self.K, self.man_dim),\n",
    "                                                          dtype=tf.float32),\n",
    "                                 trainable=True)\n",
    "\n",
    "    def process_dgm(self, dgm, ind):\n",
    "        '''\n",
    "            Compute the representation of a diagram\n",
    "        '''\n",
    "        padded_dgm = tf.pad(dgm, paddings=[[0, 0], [0, 0], [0, self.man_dim - 2]])\n",
    "        man_dgm = self.manifold.parametrization(padded_dgm)\n",
    "\n",
    "        man_dgm = tf.expand_dims(man_dgm, axis=-2)\n",
    "        man_dgm = tf.repeat(man_dgm, repeats=self.K, axis=-2)\n",
    "        \n",
    "        theta = tf.gather(self.theta, indices=ind, axis=0)\n",
    "        \n",
    "        # Add lernable vars\n",
    "        x = tf.add(man_dgm, theta)\n",
    "\n",
    "        # Make sure that point still belongs to the manifold\n",
    "        x = self.manifold.project_to_manifold(x)\n",
    "        \n",
    "        # Transfer to tangent space\n",
    "        tangent_x = self.manifold.log_map_x(self.x_o, x)\n",
    "        reshaped_tangent_x = tf.reshape(tangent_x,\n",
    "                                        shape=[-1, self.max_num_of_points,\n",
    "                                               self.K, self.man_dim])\n",
    "        # Sum out diagram points\n",
    "        sums = tf.reduce_sum(tangent_x, axis=1)\n",
    "\n",
    "        # Transform back to manifold\n",
    "        x_dgm = self.manifold.exp_map_x(self.x_o, sums)\n",
    "\n",
    "        # Transform to eucledian\n",
    "        y_dgm = self.manifold.chart(x_dgm)\n",
    "\n",
    "        return tf.reshape(y_dgm, shape=[-1, self.K, self.man_dim])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'projection_bases': self.K,\n",
    "            'num_of_hom': self.num_of_hom,\n",
    "            'max_num_of_points': self.max_num_of_points,\n",
    "            'man_dim': self.man_dim,\n",
    "            'manifold': self.manifold,\n",
    "            'x_0': self.x_o,\n",
    "            'theta': self.theta\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "            Call method of Keras Layers\n",
    "        '''\n",
    "        # Get the diagrams for the two homology classes\n",
    "        # Two classes are sufficient for images/graphs\n",
    "        # TODO generalize to m classes in the future\n",
    "        dgm_0 = inputs[:, 0, :, :]  # zero-th homology class\n",
    "        dgm_1 = inputs[:, 1, :, :]  # first homology class\n",
    "\n",
    "        # Get and concat outputs\n",
    "        out_0 = self.process_dgm(dgm_0, 0)\n",
    "        out_1 = self.process_dgm(dgm_1, 1)\n",
    "        out_0 = tf.expand_dims(out_0, axis=1)\n",
    "        out_1 = tf.expand_dims(out_1, axis=1)\n",
    "        out = tf.concat([out_0, out_1], axis=1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_images(images_id):\n",
    "    '''\n",
    "        Obtains train/test data for the given image set using the provided filtration paramers\n",
    "    '''\n",
    "\n",
    "    # Load data\n",
    "    if images_id == 'fashion_mnist':\n",
    "        train_images, train_labels, test_images, test_labels = utils.get_mnist_data(fashion=True)\n",
    "    elif images_id == 'cifar10':\n",
    "        train_images, train_labels, test_images, test_labels = utils.get_cifar()\n",
    "    elif images_id == 'mpeg7':\n",
    "        train_images, train_labels, test_images, test_labels = utils.get_mpeg_data(new_size=32)\n",
    "    else:  # Load mnist by default\n",
    "        train_images, train_labels, test_images, test_labels = utils.get_mnist_data()\n",
    "\n",
    "    ## Set the params of the filtrations\n",
    "    # Height filtration\n",
    "    num_of_vects = 30\n",
    "    angles = np.linspace(0, math.pi / 2, num_of_vects)\n",
    "    directions = [[round(math.cos(theta), 3), round(math.sin(theta), 3)] for theta in angles]\n",
    "    directions = np.array(directions)\n",
    "\n",
    "    # Radial filtration\n",
    "    center = np.array([[10, 10], [10, 20], [15, 15], [20, 10], [20, 20]])\n",
    "    radius = np.array([5, 8, 10, 12, 15])\n",
    "    center = np.array([])\n",
    "    radius = np.array([])\n",
    "\n",
    "    # Erosion filtration\n",
    "    n_iter_er = np.array([1, 2, 3, 50])\n",
    "    n_iter_er = np.array([])\n",
    "\n",
    "    # Dilation filtration\n",
    "    n_iter_dil = np.array([1, 3, 5, 10, 50])\n",
    "    n_iter_dil = np.array([])\n",
    "\n",
    "    # Set filtration params\n",
    "    params = {'cubical': None,\n",
    "              'height': directions,\n",
    "              'radial': {'center': center,\n",
    "                         'radius': radius\n",
    "                         },\n",
    "              'erosion': n_iter_er,\n",
    "              'dilation': n_iter_dil\n",
    "              }\n",
    "\n",
    "    # Concat train/test\n",
    "    N_train = train_images.shape[0]\n",
    "    images = np.concatenate([train_images, test_images], axis=0)\n",
    "\n",
    "    # Get PDs for all\n",
    "    image_pd = ImagePDiagram(images, fil_parms=params, images_id=images_id)\n",
    "    diagrams = image_pd.get_pds()\n",
    "\n",
    "    # Split them\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    for diagram in diagrams:\n",
    "        x_train.append(diagram[:N_train])\n",
    "        x_test.append(diagram[N_train:])\n",
    "\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded persistence diagrams.\n"
     ]
    }
   ],
   "source": [
    "data_id = 'mpeg7'\n",
    "x_train, y_train, x_test, y_test = get_data_images(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2, 20, 2)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_dim = 2\n",
    "K = 10\n",
    "manifold = 'poincare'\n",
    "units = [256, 128, 70]\n",
    "\n",
    "num_of_filtrations = len(x_train)\n",
    "num_of_hom = 2  # = x_train[0].shape[1]\n",
    "max_num_of_points = []\n",
    "for i in range(num_of_filtrations):\n",
    "    max_num_of_points.append(x_train[i].shape[2])\n",
    "input_shape = [num_of_filtrations, num_of_hom, max_num_of_points]\n",
    "\n",
    "# Get input shapes\n",
    "num_of_fil = input_shape[0]\n",
    "num_of_hom = input_shape[1]\n",
    "max_num_of_points = input_shape[2]\n",
    "\n",
    "# Setup an input for each filtration\n",
    "in_layer = []\n",
    "inputs = []\n",
    "for i in range(num_of_fil):\n",
    "        layer_input_shape = [num_of_hom, max_num_of_points[i], 2]\n",
    "        cur_input = tf.keras.Input(shape=layer_input_shape)\n",
    "\n",
    "        # Create Persistent Manifold Layers\n",
    "        pm_layer = PManifold(max_num_of_points=max_num_of_points[i], man_dim=man_dim,\n",
    "                             num_of_hom=num_of_hom, K=K, manifold=manifold)\n",
    "        inputs.append(cur_input)\n",
    "        in_layer.append(pm_layer(cur_input))\n",
    "\n",
    "\n",
    "# Flatten\n",
    "in_layer_2 = tf.concat(in_layer, axis=1)\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(in_layer_2)\n",
    "\n",
    "# First dense\n",
    "dense1 = tf.keras.layers.Dense(units[0],\n",
    "                                    activation='relu')(flat)\n",
    "\n",
    "# Batch norm\n",
    "batch_norm = tf.keras.layers.BatchNormalization()(dense1)\n",
    "\n",
    "# Second dense\n",
    "dense2 = tf.keras.layers.Dense(units[1],\n",
    "                                    activation='relu')(batch_norm)\n",
    "\n",
    "# Dropout\n",
    "dropout = tf.keras.layers.Dropout(0.2)(dense2)\n",
    "\n",
    "# Out\n",
    "out_layer = tf.keras.layers.Dense(units=units[2])(dropout)\n",
    "\n",
    "model= tf.keras.Model(inputs=[inputs], outputs=out_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_724 (InputLayer)          [(None, 2, 110, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_725 (InputLayer)          [(None, 2, 35, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_726 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_727 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_728 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_729 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_730 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_731 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_732 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_733 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_734 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_735 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_736 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_737 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_738 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_739 (InputLayer)          [(None, 2, 43, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_740 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_741 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_742 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_743 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_744 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_745 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_746 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_747 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_748 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_749 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_750 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_751 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_752 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_753 (InputLayer)          [(None, 2, 39, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_754 (InputLayer)          [(None, 2, 35, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_720 (PManifold)      (None, 2, 10, 2)     40          input_724[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_721 (PManifold)      (None, 2, 10, 2)     40          input_725[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_722 (PManifold)      (None, 2, 10, 2)     40          input_726[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_723 (PManifold)      (None, 2, 10, 2)     40          input_727[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_724 (PManifold)      (None, 2, 10, 2)     40          input_728[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_725 (PManifold)      (None, 2, 10, 2)     40          input_729[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_726 (PManifold)      (None, 2, 10, 2)     40          input_730[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_727 (PManifold)      (None, 2, 10, 2)     40          input_731[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_728 (PManifold)      (None, 2, 10, 2)     40          input_732[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_729 (PManifold)      (None, 2, 10, 2)     40          input_733[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_730 (PManifold)      (None, 2, 10, 2)     40          input_734[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_731 (PManifold)      (None, 2, 10, 2)     40          input_735[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_732 (PManifold)      (None, 2, 10, 2)     40          input_736[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_733 (PManifold)      (None, 2, 10, 2)     40          input_737[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_734 (PManifold)      (None, 2, 10, 2)     40          input_738[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_735 (PManifold)      (None, 2, 10, 2)     40          input_739[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_736 (PManifold)      (None, 2, 10, 2)     40          input_740[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_737 (PManifold)      (None, 2, 10, 2)     40          input_741[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_738 (PManifold)      (None, 2, 10, 2)     40          input_742[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_739 (PManifold)      (None, 2, 10, 2)     40          input_743[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_740 (PManifold)      (None, 2, 10, 2)     40          input_744[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_741 (PManifold)      (None, 2, 10, 2)     40          input_745[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_742 (PManifold)      (None, 2, 10, 2)     40          input_746[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_743 (PManifold)      (None, 2, 10, 2)     40          input_747[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_744 (PManifold)      (None, 2, 10, 2)     40          input_748[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_745 (PManifold)      (None, 2, 10, 2)     40          input_749[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_746 (PManifold)      (None, 2, 10, 2)     40          input_750[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_747 (PManifold)      (None, 2, 10, 2)     40          input_751[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_748 (PManifold)      (None, 2, 10, 2)     40          input_752[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_749 (PManifold)      (None, 2, 10, 2)     40          input_753[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_manifold_750 (PManifold)      (None, 2, 10, 2)     40          input_754[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_54 (TensorFl [(None, 62, 10, 2)]  0           p_manifold_720[0][0]             \n",
      "                                                                 p_manifold_721[0][0]             \n",
      "                                                                 p_manifold_722[0][0]             \n",
      "                                                                 p_manifold_723[0][0]             \n",
      "                                                                 p_manifold_724[0][0]             \n",
      "                                                                 p_manifold_725[0][0]             \n",
      "                                                                 p_manifold_726[0][0]             \n",
      "                                                                 p_manifold_727[0][0]             \n",
      "                                                                 p_manifold_728[0][0]             \n",
      "                                                                 p_manifold_729[0][0]             \n",
      "                                                                 p_manifold_730[0][0]             \n",
      "                                                                 p_manifold_731[0][0]             \n",
      "                                                                 p_manifold_732[0][0]             \n",
      "                                                                 p_manifold_733[0][0]             \n",
      "                                                                 p_manifold_734[0][0]             \n",
      "                                                                 p_manifold_735[0][0]             \n",
      "                                                                 p_manifold_736[0][0]             \n",
      "                                                                 p_manifold_737[0][0]             \n",
      "                                                                 p_manifold_738[0][0]             \n",
      "                                                                 p_manifold_739[0][0]             \n",
      "                                                                 p_manifold_740[0][0]             \n",
      "                                                                 p_manifold_741[0][0]             \n",
      "                                                                 p_manifold_742[0][0]             \n",
      "                                                                 p_manifold_743[0][0]             \n",
      "                                                                 p_manifold_744[0][0]             \n",
      "                                                                 p_manifold_745[0][0]             \n",
      "                                                                 p_manifold_746[0][0]             \n",
      "                                                                 p_manifold_747[0][0]             \n",
      "                                                                 p_manifold_748[0][0]             \n",
      "                                                                 p_manifold_749[0][0]             \n",
      "                                                                 p_manifold_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 1240)         0           tf_op_layer_concat_54[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_185 (Dense)               (None, 256)          317696      flatten_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 256)          1024        dense_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_186 (Dense)               (None, 128)          32896       batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 128)          0           dense_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (None, 70)           9030        dropout_53[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 361,886\n",
      "Trainable params: 361,374\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hdd/panos/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'gradient_tape/model_51/p_manifold_671/DynamicStitch' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2331\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2333\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'gradient_tape/model_51/p_manifold_671/DynamicStitch' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-1037f6536255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         if x is not None)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/util/object_identity.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=200,batch_size=32,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 4.2650 - accuracy: 0.0127 - val_loss: 4.2550 - val_accuracy: 0.0071\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.2214 - accuracy: 0.0238 - val_loss: 4.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.1907 - accuracy: 0.0270 - val_loss: 4.2678 - val_accuracy: 0.0143\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.1581 - accuracy: 0.0333 - val_loss: 4.2831 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.1307 - accuracy: 0.0405 - val_loss: 4.3002 - val_accuracy: 0.0071\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0935 - accuracy: 0.0421 - val_loss: 4.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0716 - accuracy: 0.0429 - val_loss: 4.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0438 - accuracy: 0.0516 - val_loss: 4.3544 - val_accuracy: 0.0071\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0186 - accuracy: 0.0492 - val_loss: 4.3602 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.9952 - accuracy: 0.0571 - val_loss: 4.3774 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.9676 - accuracy: 0.0587 - val_loss: 4.3915 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.9464 - accuracy: 0.0683 - val_loss: 4.4061 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.9258 - accuracy: 0.0722 - val_loss: 4.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.9070 - accuracy: 0.0722 - val_loss: 4.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8897 - accuracy: 0.0770 - val_loss: 4.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8613 - accuracy: 0.0865 - val_loss: 4.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8538 - accuracy: 0.0921 - val_loss: 4.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8349 - accuracy: 0.0944 - val_loss: 4.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8270 - accuracy: 0.0937 - val_loss: 4.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8015 - accuracy: 0.0929 - val_loss: 4.5116 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7956 - accuracy: 0.0984 - val_loss: 4.5288 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7733 - accuracy: 0.1032 - val_loss: 4.5435 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7620 - accuracy: 0.1040 - val_loss: 4.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7400 - accuracy: 0.1111 - val_loss: 4.5690 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7298 - accuracy: 0.1103 - val_loss: 4.5841 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7204 - accuracy: 0.1103 - val_loss: 4.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.7085 - accuracy: 0.1238 - val_loss: 4.6119 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6931 - accuracy: 0.1119 - val_loss: 4.6193 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6804 - accuracy: 0.1175 - val_loss: 4.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6775 - accuracy: 0.1294 - val_loss: 4.6438 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6537 - accuracy: 0.1302 - val_loss: 4.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6400 - accuracy: 0.1302 - val_loss: 4.6706 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6403 - accuracy: 0.1365 - val_loss: 4.6953 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6264 - accuracy: 0.1349 - val_loss: 4.7013 - val_accuracy: 0.0071\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.1405 - val_loss: 4.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5989 - accuracy: 0.1389 - val_loss: 4.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5973 - accuracy: 0.1405 - val_loss: 4.7439 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5891 - accuracy: 0.1500 - val_loss: 4.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5826 - accuracy: 0.1476 - val_loss: 4.7729 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5522 - accuracy: 0.1468 - val_loss: 4.7794 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5547 - accuracy: 0.1532 - val_loss: 4.7938 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5388 - accuracy: 0.1476 - val_loss: 4.8025 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5393 - accuracy: 0.1611 - val_loss: 4.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5332 - accuracy: 0.1500 - val_loss: 4.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5284 - accuracy: 0.1500 - val_loss: 4.8411 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5149 - accuracy: 0.1571 - val_loss: 4.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5108 - accuracy: 0.1635 - val_loss: 4.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.5020 - accuracy: 0.1595 - val_loss: 4.9050 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4954 - accuracy: 0.1651 - val_loss: 4.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4808 - accuracy: 0.1651 - val_loss: 4.9327 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4778 - accuracy: 0.1698 - val_loss: 4.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4777 - accuracy: 0.1690 - val_loss: 4.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4623 - accuracy: 0.1643 - val_loss: 4.9700 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4687 - accuracy: 0.1659 - val_loss: 4.9837 - val_accuracy: 0.0071\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4498 - accuracy: 0.1698 - val_loss: 4.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4496 - accuracy: 0.1675 - val_loss: 5.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4334 - accuracy: 0.1730 - val_loss: 5.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4193 - accuracy: 0.1762 - val_loss: 5.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4272 - accuracy: 0.1722 - val_loss: 5.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4273 - accuracy: 0.1762 - val_loss: 5.0532 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4110 - accuracy: 0.1786 - val_loss: 5.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4090 - accuracy: 0.1786 - val_loss: 5.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4154 - accuracy: 0.1730 - val_loss: 5.1012 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3930 - accuracy: 0.1802 - val_loss: 5.1115 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3925 - accuracy: 0.1794 - val_loss: 5.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3892 - accuracy: 0.1802 - val_loss: 5.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3834 - accuracy: 0.1905 - val_loss: 5.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3687 - accuracy: 0.1849 - val_loss: 5.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3766 - accuracy: 0.1865 - val_loss: 5.1593 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3664 - accuracy: 0.1897 - val_loss: 5.1794 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3691 - accuracy: 0.1825 - val_loss: 5.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3530 - accuracy: 0.1921 - val_loss: 5.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3522 - accuracy: 0.1897 - val_loss: 5.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3526 - accuracy: 0.1849 - val_loss: 5.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3490 - accuracy: 0.1921 - val_loss: 5.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3553 - accuracy: 0.1921 - val_loss: 5.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3304 - accuracy: 0.1944 - val_loss: 5.2636 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3291 - accuracy: 0.1952 - val_loss: 5.2795 - val_accuracy: 0.0071\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3177 - accuracy: 0.1937 - val_loss: 5.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3268 - accuracy: 0.1944 - val_loss: 5.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3147 - accuracy: 0.1976 - val_loss: 5.3081 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3160 - accuracy: 0.1968 - val_loss: 5.3269 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3167 - accuracy: 0.1937 - val_loss: 5.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3041 - accuracy: 0.1992 - val_loss: 5.3726 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3019 - accuracy: 0.2016 - val_loss: 5.3745 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3044 - accuracy: 0.2000 - val_loss: 5.3869 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2926 - accuracy: 0.2056 - val_loss: 5.3969 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2972 - accuracy: 0.2040 - val_loss: 5.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2872 - accuracy: 0.2024 - val_loss: 5.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2824 - accuracy: 0.2008 - val_loss: 5.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2652 - accuracy: 0.2095 - val_loss: 5.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2819 - accuracy: 0.2087 - val_loss: 5.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2677 - accuracy: 0.2071 - val_loss: 5.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2818 - accuracy: 0.2063 - val_loss: 5.5035 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2702 - accuracy: 0.2095 - val_loss: 5.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2562 - accuracy: 0.2111 - val_loss: 5.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2681 - accuracy: 0.2167 - val_loss: 5.5190 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2646 - accuracy: 0.2167 - val_loss: 5.5393 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2636 - accuracy: 0.2135 - val_loss: 5.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2562 - accuracy: 0.2214 - val_loss: 5.5633 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2617 - accuracy: 0.2159 - val_loss: 5.5736 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2436 - accuracy: 0.2151 - val_loss: 5.5844 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2358 - accuracy: 0.2159 - val_loss: 5.5960 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2493 - accuracy: 0.2151 - val_loss: 5.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2544 - accuracy: 0.2214 - val_loss: 5.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2436 - accuracy: 0.2151 - val_loss: 5.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2237 - accuracy: 0.2230 - val_loss: 5.6485 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2354 - accuracy: 0.2214 - val_loss: 5.6664 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2246 - accuracy: 0.2222 - val_loss: 5.6715 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2285 - accuracy: 0.2238 - val_loss: 5.6923 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2213 - accuracy: 0.2294 - val_loss: 5.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2154 - accuracy: 0.2190 - val_loss: 5.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2183 - accuracy: 0.2302 - val_loss: 5.7201 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2149 - accuracy: 0.2214 - val_loss: 5.7259 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2115 - accuracy: 0.2286 - val_loss: 5.7436 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2019 - accuracy: 0.2278 - val_loss: 5.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2013 - accuracy: 0.2246 - val_loss: 5.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2036 - accuracy: 0.2238 - val_loss: 5.7738 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2120 - accuracy: 0.2246 - val_loss: 5.7806 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2032 - accuracy: 0.2286 - val_loss: 5.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1862 - accuracy: 0.2270 - val_loss: 5.8068 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1921 - accuracy: 0.2341 - val_loss: 5.8081 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1976 - accuracy: 0.2310 - val_loss: 5.8480 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1817 - accuracy: 0.2349 - val_loss: 5.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1696 - accuracy: 0.2325 - val_loss: 5.8493 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1748 - accuracy: 0.2317 - val_loss: 5.8796 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1852 - accuracy: 0.2325 - val_loss: 5.8773 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1741 - accuracy: 0.2302 - val_loss: 5.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1712 - accuracy: 0.2333 - val_loss: 5.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1591 - accuracy: 0.2317 - val_loss: 5.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1727 - accuracy: 0.2373 - val_loss: 5.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1732 - accuracy: 0.2310 - val_loss: 5.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1647 - accuracy: 0.2333 - val_loss: 5.9466 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1636 - accuracy: 0.2389 - val_loss: 5.9476 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1556 - accuracy: 0.2333 - val_loss: 5.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1717 - accuracy: 0.2381 - val_loss: 5.9886 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1482 - accuracy: 0.2389 - val_loss: 5.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1447 - accuracy: 0.2357 - val_loss: 5.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1529 - accuracy: 0.2365 - val_loss: 6.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1552 - accuracy: 0.2413 - val_loss: 6.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1384 - accuracy: 0.2444 - val_loss: 6.0369 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1477 - accuracy: 0.2381 - val_loss: 6.0478 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1453 - accuracy: 0.2365 - val_loss: 6.0587 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1496 - accuracy: 0.2405 - val_loss: 6.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1457 - accuracy: 0.2413 - val_loss: 6.0731 - val_accuracy: 0.0071\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1253 - accuracy: 0.2468 - val_loss: 6.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1334 - accuracy: 0.2444 - val_loss: 6.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1378 - accuracy: 0.2437 - val_loss: 6.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1398 - accuracy: 0.2452 - val_loss: 6.1188 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1293 - accuracy: 0.2468 - val_loss: 6.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1264 - accuracy: 0.2500 - val_loss: 6.1612 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1293 - accuracy: 0.2516 - val_loss: 6.1440 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1288 - accuracy: 0.2500 - val_loss: 6.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1158 - accuracy: 0.2500 - val_loss: 6.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1227 - accuracy: 0.2532 - val_loss: 6.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1251 - accuracy: 0.2476 - val_loss: 6.1985 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0949 - accuracy: 0.2508 - val_loss: 6.2022 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1092 - accuracy: 0.2524 - val_loss: 6.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1130 - accuracy: 0.2476 - val_loss: 6.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1068 - accuracy: 0.2548 - val_loss: 6.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1193 - accuracy: 0.2524 - val_loss: 6.2465 - val_accuracy: 0.0071\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1105 - accuracy: 0.2476 - val_loss: 6.2548 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0996 - accuracy: 0.2484 - val_loss: 6.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1060 - accuracy: 0.2532 - val_loss: 6.2713 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1130 - accuracy: 0.2516 - val_loss: 6.2945 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0832 - accuracy: 0.2563 - val_loss: 6.3016 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1155 - accuracy: 0.2500 - val_loss: 6.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0937 - accuracy: 0.2516 - val_loss: 6.3176 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1041 - accuracy: 0.2579 - val_loss: 6.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1005 - accuracy: 0.2603 - val_loss: 6.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0926 - accuracy: 0.2540 - val_loss: 6.3561 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0821 - accuracy: 0.2571 - val_loss: 6.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0970 - accuracy: 0.2595 - val_loss: 6.3836 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0937 - accuracy: 0.2563 - val_loss: 6.3796 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0912 - accuracy: 0.2611 - val_loss: 6.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0815 - accuracy: 0.2619 - val_loss: 6.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0793 - accuracy: 0.2595 - val_loss: 6.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0717 - accuracy: 0.2611 - val_loss: 6.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0847 - accuracy: 0.2619 - val_loss: 6.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0855 - accuracy: 0.2683 - val_loss: 6.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0834 - accuracy: 0.2659 - val_loss: 6.4725 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0878 - accuracy: 0.2643 - val_loss: 6.4776 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0692 - accuracy: 0.2595 - val_loss: 6.4840 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0667 - accuracy: 0.2595 - val_loss: 6.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0739 - accuracy: 0.2595 - val_loss: 6.4986 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0670 - accuracy: 0.2619 - val_loss: 6.5094 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0693 - accuracy: 0.2619 - val_loss: 6.5179 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0661 - accuracy: 0.2611 - val_loss: 6.5292 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0646 - accuracy: 0.2659 - val_loss: 6.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0777 - accuracy: 0.2635 - val_loss: 6.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0748 - accuracy: 0.2635 - val_loss: 6.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0621 - accuracy: 0.2635 - val_loss: 6.5676 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0692 - accuracy: 0.2683 - val_loss: 6.5712 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0545 - accuracy: 0.2635 - val_loss: 6.5911 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0528 - accuracy: 0.2635 - val_loss: 6.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0725 - accuracy: 0.2651 - val_loss: 6.6048 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0365 - accuracy: 0.2683 - val_loss: 6.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0496 - accuracy: 0.2675 - val_loss: 6.6126 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0558 - accuracy: 0.2667 - val_loss: 6.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0475 - accuracy: 0.2659 - val_loss: 6.6522 - val_accuracy: 0.0000e+00\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_46 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            multiple                  56448     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            multiple                  9030      \n",
      "=================================================================\n",
      "Total params: 65,478\n",
      "Trainable params: 65,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(70))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model1.fit(x_train[0], y_train, epochs=200, \n",
    "                    validation_data=(x_test[0], y_test))\n",
    "model1.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
